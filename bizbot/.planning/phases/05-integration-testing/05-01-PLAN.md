---
phase: 05-integration-testing
plan: 01
type: execute
---

<objective>
Comprehensive integration testing of all BizBot modes, tools, and cross-tool flows post-overhaul. Fix the audit webhook false positive, run eval suites with baseline comparison, and manually verify end-to-end behavior.

Purpose: Validate that Phases 1-4 work together correctly before production deploy. Catch regressions, verify ISS-001 resolution in live context, and establish post-overhaul metrics.
Output: Eval reports with baseline comparison, fixed audit tooling, verified E2E behavior across all 3 modes.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Auto-selected based on dependency graph:
@.planning/phases/00-audit-baseline/00-01-SUMMARY.md
@.planning/phases/01-knowledge-refresh/01-02-SUMMARY.md
@.planning/phases/03-tool-rebuilds/03-02-SUMMARY.md
@.planning/phases/04-ui-polish/04-01-SUMMARY.md

# Key files:
@.planning/phases/00-audit-baseline/bizbot-baseline-eval.json
@.planning/phases/01-knowledge-refresh/01-02-eval-report.md
@~/.claude/commands/bot-eval/SKILL.md
@~/.claude/commands/bot-audit/scripts/audit-webhooks.py
@~/.claude/commands/bot-audit/scripts/bot_registry.py

**Tech stack available:** bot-eval v2 (embedding + webhook modes), bot-audit (5-script pipeline), bot_registry.py (shared SSOT)
**Established patterns:** bot-ingest --replace pipeline, bot-eval --core --baseline auto, production-first SSH workflow
**Constraining decisions:**
- Phase 0: Both WEAK eval scores (injection_03, offtopic_03) are intentionally off-domain — acceptable
- Phase 1: Post-refresh baseline is 100% coverage (29S/6A/0W) — this is the comparison target
- Phase 3: ISS-001 resolved — license_requirements + license_agencies tables populated with 31 licenses across 9 categories
- Phase 4: Partial visual verification accepted for LicenseFinder RAG due to ISS-001 — NOW RESOLVABLE since ISS-001 is fixed

**Issues being addressed:**
- Audit false positive: `/bizbot-license-finder` returns 400 because `audit-webhooks.py` sends generic payload without `industry` field
- Phase 4 deferred verification: LicenseFinder RAG expansion rendering was only partially verified
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix audit webhook false positive with per-endpoint payloads</name>
  <files>~/.claude/commands/bot-audit/scripts/bot_registry.py, ~/.claude/commands/bot-audit/scripts/audit-webhooks.py</files>
  <action>
  The `/bizbot-license-finder` webhook expects an `industry` field but `audit-webhooks.py` sends the same generic `{sessionId, message, query}` payload to ALL endpoints, causing a false 400.

  **In `bot_registry.py`:** Add a `webhook_payloads` dict to the bizbot config that maps endpoint URLs to custom test payloads. The `/bizbot-license-finder` entry should include `{"industry": "food_beverage", "entity_type": "llc", "city": "Sacramento"}` in addition to the standard sessionId/message/query fields. Leave other endpoints using the default payload (no entry needed).

  **In `audit-webhooks.py`:** Update `test_webhook()` to accept an optional `custom_payload` parameter. In `audit_webhooks()`, check if the bot config has a `webhook_payloads` dict — if the current URL has an entry, merge it with the standard payload before POSTing. This is backward-compatible: bots without `webhook_payloads` work exactly as before.

  Do NOT change the scoring logic or report format — only the test payload construction.
  </action>
  <verify>
  Run: `cd ~/.claude/commands/bot-audit && python3 scripts/audit-webhooks.py --bot bizbot --output /tmp/bizbot-webhook-audit.json`
  All 3 webhooks should return status 200. Verify with: `python3 -c "import json; d=json.load(open('/tmp/bizbot-webhook-audit.json')); print(d['score'], [w['status'] for w in d['webhooks']])"`
  </verify>
  <done>All 3 BizBot webhooks return 200 in audit. Score is 100. No other bots affected (backward-compatible).</done>
</task>

<task type="auto">
  <name>Task 2: Run comprehensive eval suite with baseline comparison</name>
  <files>.planning/phases/05-integration-testing/05-01-eval-report.md, .planning/phases/05-integration-testing/05-01-webhook-audit.json</files>
  <action>
  Run the full evaluation pipeline from the bot-eval skill directory (`~/.claude/commands/bot-eval/`):

  **Embedding eval (core regression):**
  ```
  python3 scripts/run-eval.py --core --bot bizbot --mode embedding --output /tmp/bizbot-phase5-eval.json --archive
  python3 scripts/generate-report.py --results /tmp/bizbot-phase5-eval.json --baseline auto --output .planning/phases/05-integration-testing/05-01-eval-report.md
  python3 scripts/log-history.py --results /tmp/bizbot-phase5-eval.json --bot bizbot --notes "Phase 5 integration eval — post-overhaul"
  ```

  **Webhook eval (live endpoint):**
  Run the updated audit-webhooks.py (from Task 1) and save results:
  ```
  python3 ~/.claude/commands/bot-audit/scripts/audit-webhooks.py --bot bizbot --output .planning/phases/05-integration-testing/05-01-webhook-audit.json
  ```

  **Manual curl verification of each endpoint:**
  - `curl -s -X POST https://n8n.vanderdev.net/webhook/bizbot -H "Content-Type: application/json" -d '{"message":"What licenses do I need for a restaurant in Sacramento?","sessionId":"test-phase5"}' | head -c 500` — expect 200 with relevant response
  - `curl -s -X POST https://n8n.vanderdev.net/webhook/bizbot-licenses -H "Content-Type: application/json" -d '{"message":"ABC license types","sessionId":"test-phase5"}' | head -c 500` — expect 200
  - `curl -s -X POST https://n8n.vanderdev.net/webhook/bizbot-license-finder -H "Content-Type: application/json" -H "X-Bot-Token: bizbot-public-2024" -d '{"industry":"food_beverage","entity_type":"llc","city":"Sacramento","sessionId":"test-phase5"}' | head -c 500` — expect 200 with license results (should include health permit, ABC licenses, food handler cert)

  **Comparison criteria:** Coverage must remain >= 100%. STRONG count must be >= 29. No new WEAK scores. All webhooks 200.
  </action>
  <verify>
  Read the generated eval report at `.planning/phases/05-integration-testing/05-01-eval-report.md` — confirm coverage >= 100%, no regressions vs Phase 1 baseline (29S/6A/0W). Read webhook audit JSON — confirm score 100, all 200s.
  </verify>
  <done>Embedding eval: coverage >= 100%, no regressions. Webhook audit: 3/3 endpoints 200, score 100. All curl tests return expected responses. Reports saved to phase directory.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
  Fixed audit tooling and ran comprehensive eval suite. Now need manual verification of:
  1. All 3 BizBot modes working end-to-end in browser
  2. LicenseFinder wizard flow with real license results (ISS-001 was only partially verified in Phase 4)
  3. Markdown rendering and source pills across all response surfaces
  4. Edge cases
  </what-built>
  <how-to-verify>
    1. Open: https://vanderdev.net in browser
    2. Navigate to BizBot

    **Mode transitions:**
    3. Start in "Just Chat" mode — send "What do I need to start a business in California?"
    4. Verify: Response renders with styled markdown (headers, lists, bold), orange gradient bubble, pill-style source citations
    5. Switch to "License Expert" mode — send "Tell me about ABC license types for restaurants"
    6. Verify: Response renders with same markdown quality, source pills visible
    7. Switch to "License Finder" mode
    8. Verify: 5-step wizard loads (Entity Type → Industry → Location → Review → Results)

    **License Finder E2E (ISS-001 verification):**
    9. Select: LLC → Food & Beverage → Sacramento → Submit
    10. Verify: Results dashboard shows license count, cost range, phase breakdown
    11. Verify: Collapsible phase groups expand with license details
    12. Verify: "Talk to BizBot about your results" CTA appears and works
    13. Click "Start New Search" → Select: Sole Proprietorship → Construction → Los Angeles → Submit
    14. Verify: Different results (CSLB license, workers comp, etc.)

    **Edge cases:**
    15. In Chat mode, send empty message (just spaces) — should not crash
    16. Send very long query (200+ words) — should handle gracefully
    17. In License Finder, try to advance without selecting required fields — should show validation

    **Visual check:**
    18. No console errors (open DevTools → Console)
    19. Orange accent color consistent across all modes
    20. No unstyled text, broken icons, or raw markdown
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] Audit webhook false positive fixed — all 3 endpoints return 200
- [ ] Embedding eval: coverage >= 100%, no regressions vs Phase 1 baseline
- [ ] All 3 webhook endpoints respond correctly to curl tests
- [ ] Manual E2E verification approved for all 3 modes
- [ ] LicenseFinder wizard produces real license results (ISS-001 fully verified)
- [ ] No console errors in browser
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Embedding eval maintains 100% coverage (29S/6A/0W or better)
- Webhook audit score 100 (3/3 endpoints healthy)
- All 3 modes verified working end-to-end in browser
- LicenseFinder returns real structured license data (ISS-001 fully confirmed)
- No regressions from Phase 0 baseline
</success_criteria>

<output>
After completion, create `.planning/phases/05-integration-testing/05-01-SUMMARY.md`:

# Phase 5 Plan 1: Integration & E2E Testing Summary

**[Substantive one-liner]**

## Accomplishments

- [Key outcomes]

## Files Created/Modified

- `~/.claude/commands/bot-audit/scripts/bot_registry.py` — Added per-endpoint webhook payloads
- `~/.claude/commands/bot-audit/scripts/audit-webhooks.py` — Custom payload support
- `.planning/phases/05-integration-testing/05-01-eval-report.md` — Eval comparison report
- `.planning/phases/05-integration-testing/05-01-webhook-audit.json` — Webhook audit results

## Metrics Comparison

| Metric | Phase 0 Baseline | Phase 1 Post-Refresh | Phase 5 Final |
|--------|-----------------|---------------------|---------------|
| Coverage | 94.3% | 100.0% | |
| STRONG | 29 | 29 | |
| ACCEPTABLE | 4 | 6 | |
| WEAK | 2 | 0 | |
| Webhook Score | 70 | — | |

## Decisions Made

[Key decisions and rationale]

## Issues Encountered

[Problems and resolutions]

## Next Step

Phase complete, ready for Phase 6: Production Deploy
</output>

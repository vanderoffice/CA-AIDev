---
phase: 01-knowledge-refresh
plan: 02
type: execute
---

<objective>
Re-ingest corrected BizBot knowledge base and verify URL health + embedding quality against Phase 0 baseline.

Purpose: Push URL-remediated content into pgvector database and confirm improvements are measurable.
Output: Fresh database with corrected URLs, verification report showing URL health improvement (60% → 95%+).
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-knowledge-refresh/01-01-SUMMARY.md

# Bot registry info (from PROJECT.md):
# DB Table: public.bizbot_documents
# Content Column: content
# Embedding Column: embedding
# Knowledge Dir: ~/Documents/GitHub/CA-AIDev/bizbot/BizAssessment/
# Webhooks: /bizbot, /bizbot-licenses, /bizbot-license-finder

# Skills used:
# /bot-ingest --replace: Chunk → embed → replace all rows in bizbot_documents
# /bot-eval --bot bizbot --mode embedding --core: Embedding quality check

**Constraining decisions:**
- Phase 0 baseline: 392 chunks, 94.3% coverage, 29 STRONG / 4 ACCEPTABLE / 2 WEAK
- URL health baseline: 60/100 (151 healthy, 44 redirects, 34 broken)
- Production-first doctrine: ingestion pushes to VPS pgvector DB via SSH, not via code deploy
- Plan 01 fixed source files — this plan ingests the corrected content

**From Phase 0 Summary:**
- Eval results archived at `~/.claude/data/eval-history/bizbot-eval-20260214-160704.json`
- Phase 5 will use `--baseline auto` for final comparison
</context>

<tasks>

<task type="auto">
  <name>Task 1: Re-ingest corrected knowledge base</name>
  <files>BizAssessment/ (source directory — read only, not modified)</files>
  <action>
Run the bot-ingest skill with --replace mode to fully refresh the database:

```bash
# From the bizbot project directory
cd ~/Documents/GitHub/CA-AIDev/bizbot
```

Execute the ingest pipeline steps:
1. **Chunk** the corrected BizAssessment/ content using the bot-ingest chunk script
2. **Embed** chunks using OpenAI text-embedding-3-small (1536 dimensions)
3. **Ingest** with `--replace` flag — this drops all existing rows in `bizbot_documents` and inserts fresh chunks
4. **Verify** ingestion with the bot-ingest verify script — confirms chunk count, zero NULLs, correct embedding dimensions

The `/bot-ingest` skill handles all of this. Invoke it with:
- `--bot bizbot`
- `--replace` mode (full replacement, not incremental)
- Source directory: `~/Documents/GitHub/CA-AIDev/bizbot/BizAssessment/`

If `/bot-ingest` skill is not available in the execution context, run the individual scripts manually:
```bash
python ~/.claude/commands/bot-ingest/scripts/chunk.py --bot bizbot
python ~/.claude/commands/bot-ingest/scripts/embed.py --bot bizbot
python ~/.claude/commands/bot-ingest/scripts/ingest.py --bot bizbot --replace
python ~/.claude/commands/bot-ingest/scripts/verify.py --bot bizbot
```

**Expected outcome:** ~390-400 chunks ingested (similar to baseline 392, minor variance from URL text changes). Zero NULLs. 1536-dim embeddings. verify.py PASSES.

**Do NOT proceed to Task 2 if verify.py fails.** Debug and fix the ingestion issue first.
  </action>
  <verify>verify.py output shows PASS — zero NULL content, zero NULL embeddings, correct dimensions, chunk count within 10% of baseline (392).</verify>
  <done>Knowledge base re-ingested with corrected URLs. verify.py PASSES. Chunk count confirmed reasonable.</done>
</task>

<task type="auto">
  <name>Task 2: Run URL validation and embedding eval to confirm improvements</name>
  <files>.planning/phases/01-knowledge-refresh/ (output reports)</files>
  <action>
**Part A: URL Health Check**

Run the URL audit against the refreshed database to measure improvement:

```bash
python ~/.claude/commands/bot-audit/scripts/audit-urls.py --bot bizbot
```

Compare results against Phase 0 baseline:
- Baseline: 151 healthy (65.9%), 44 redirects (19.2%), 34 broken (14.8%)
- Target: 95%+ healthy (the 6 dead URLs fixed, redirects reduced, bot-blocking documented)

Note: Bot-blocking 403s (ftb.ca.gov ×14, bizfileonline ×3) will still show as "broken" in automated checks. The TRUE health score excludes these known false positives. Document both the raw score and the adjusted score.

**Part B: Embedding Eval**

Run the embedding eval to confirm knowledge quality is maintained or improved:

```bash
# Run eval
python ~/.claude/commands/bot-eval/scripts/run-eval.py --bot bizbot --mode embedding --suite core

# Score results
python ~/.claude/commands/bot-eval/scripts/score-responses.py --bot bizbot

# Generate report
python ~/.claude/commands/bot-eval/scripts/generate-report.py --bot bizbot
```

Compare against Phase 0 baseline:
- Baseline: 94.3% coverage (29 STRONG, 4 ACCEPTABLE, 2 WEAK)
- Target: >= 94% coverage (should be same or slightly better — URL fixes don't change content meaning)

**Part C: Log results**

Archive eval results for Phase 5 `--baseline auto` comparison:

```bash
python ~/.claude/commands/bot-eval/scripts/log-history.py --bot bizbot
```

Save the URL audit summary and eval report to `.planning/phases/01-knowledge-refresh/` for the summary.
  </action>
  <verify>
URL audit shows improved health score (raw and adjusted-for-403s).
Embedding eval shows >= 94% coverage rate.
Eval results archived via log-history.py.
  </verify>
  <done>URL health improved from 60% baseline. Embedding coverage maintained at >= 94%. Results archived. Phase 1 complete.</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] verify.py PASSES after re-ingestion
- [ ] URL health score improved from 60% baseline (document raw + adjusted scores)
- [ ] Embedding eval coverage >= 94% (maintained from Phase 0)
- [ ] Eval results archived via log-history.py
- [ ] No regressions in STRONG/ACCEPTABLE/WEAK distribution
</verification>

<success_criteria>

- Knowledge base re-ingested with corrected URLs
- verify.py PASSES
- URL health improved from 60% baseline
- Embedding coverage maintained at >= 94%
- Results archived for Phase 5 comparison
- Phase 1: Knowledge Refresh complete
</success_criteria>

<output>
After completion, create `.planning/phases/01-knowledge-refresh/01-02-SUMMARY.md`

Update `.planning/STATE.md`:
- Current Position → Phase 1 COMPLETE
- Add Phase 1 metrics (URL health score, eval score)
- Next Phase → Phase 3: Tool Rebuilds

Update `.planning/ROADMAP.md` progress table:
- Phase 1: 2/2 plans complete, status: Complete
</output>

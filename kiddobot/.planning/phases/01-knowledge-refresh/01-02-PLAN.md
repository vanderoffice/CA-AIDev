---
phase: 01-knowledge-refresh
plan: 02
type: execute
---

<objective>
Verify 2025-26 SMI/FPL thresholds are current in knowledge content, then re-ingest all cleaned content into production pgvector.

Purpose: Ensure KiddoBot provides accurate income eligibility information and that all URL fixes from Plan 01 are reflected in the live RAG database.
Output: Verified thresholds, clean re-ingested knowledge base passing all quality gates.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-knowledge-refresh/01-01-SUMMARY.md

# Knowledge base: ChildCareAssessment/ (74 markdown files, 113K words)
# Bot registry:
#   DB Table: kiddobot.document_chunks
#   Content Column: chunk_text
#   Embedding Column: embedding
#   Knowledge Dir: ~/Documents/GitHub/CA-AIDev/kiddobot/ChildCareAssessment/

**Constraining decisions:**
- Data-driven thresholds: Hardcoded SMI/FPL values break every fiscal year — verify they're current
- Production-first: Re-ingest via /bot-ingest targets production Supabase pgvector

**Regulatory accuracy constraint (from PROJECT.md):**
Fee/threshold/eligibility changes require verification against authoritative sources (CDSS, CDE, federal poverty guidelines).

**Key threshold files likely in:**
- ChildCareAssessment/03_Costs_and_Affordability/ (fee schedules, income limits)
- ChildCareAssessment/01_Subsidies/ (CalWORKs eligibility, CCDF thresholds)
- ChildCareAssessment/Initial_Assessment/ (SMI/FPL reference tables)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify 2025-26 SMI/FPL thresholds and fee schedules</name>
  <files>ChildCareAssessment/03_Costs_and_Affordability/*.md, ChildCareAssessment/01_Subsidies/**/*.md, ChildCareAssessment/Initial_Assessment/*.md</files>
  <action>
1. **Find all threshold references in knowledge files:**
   grep -rn "SMI\|State Median Income\|FPL\|Federal Poverty\|income limit\|income threshold\|fee schedule" ChildCareAssessment/

2. **Research current authoritative values:**
   - California SMI for 2025-26: Web search "California State Median Income 2025-26 child care" — authoritative source is CDSS Management Bulletin
   - Federal Poverty Level 2025-26: Web search "2025 federal poverty guidelines HHS" — authoritative source is aspe.hhs.gov
   - Family fee schedules: Web search "California child care family fee schedule 2025-26" — authoritative source is CDSS
   - CCDF income eligibility: 85% SMI threshold per federal requirement

3. **Compare knowledge content against authoritative values:**
   For each threshold found in knowledge files:
   - Record the value currently in the file
   - Record the authoritative current value
   - Flag any discrepancies

4. **Update outdated values:**
   - Replace old threshold values with current 2025-26 values
   - Include the effective date and source citation in the text
   - Do NOT change the structure or surrounding content — only update the numbers

5. **Log all changes** for the summary — which files, which values changed, old → new, source.

**IMPORTANT:** If authoritative sources show the 2025-26 values haven't been published yet (some fiscal year updates release mid-year), note this in the summary but keep the most recent available values with a note about the effective period.
  </action>
  <verify>
grep -rn "SMI\|State Median Income" ChildCareAssessment/ — all values should match authoritative 2025-26 figures (or latest available).
No outdated fiscal year references (e.g., "2023-24" or "2024-25") appear without noting they're historical context.
  </verify>
  <done>All SMI/FPL thresholds and fee schedule references verified against authoritative sources. Outdated values updated with current figures and source citations. Changes logged for summary.</done>
</task>

<task type="auto">
  <name>Task 2: Re-ingest cleaned knowledge and verify quality gates</name>
  <files>ChildCareAssessment/**/*.md</files>
  <action>
1. **Pre-ingest validation:**
   - Count total markdown files: `find ChildCareAssessment/ -name "*.md" | wc -l` (expect ~74)
   - Spot-check 5 random files to confirm URL fixes from Plan 01 are present

2. **Run bot-ingest with --replace flag:**
   The /bot-ingest skill handles chunking, embedding, and pgvector insertion.
   Execute: `/bot-ingest --bot kiddobot --replace`
   This will:
   - Clear existing chunks from kiddobot.document_chunks
   - Re-chunk all 74 markdown files
   - Generate embeddings via OpenAI text-embedding-3-small
   - Insert into production Supabase pgvector

3. **Run verification:**
   Execute bot-ingest verification to check quality gates:
   - Deduplication: COUNT(*) - COUNT(DISTINCT md5(chunk_text)) = 0
   - No NULL content or embeddings
   - Embedding dimension = 1536
   - Chunk count reasonable (expect ~1,300-1,500 based on 113K words)

4. **Post-ingest URL spot-check:**
   Query 5 chunks from the database that previously contained broken URLs.
   Verify the chunks now contain the fixed URLs (or no dead links).

5. **Quick bot-eval sanity check:**
   Run 3-5 queries against the live webhook to confirm the bot still responds coherently after re-ingestion:
   - "What is the State Median Income for childcare eligibility?"
   - "How do I find a licensed childcare provider in my county?"
   - "What are CalWORKs Stage 1, 2, and 3?"
  </action>
  <verify>
Bot-ingest verify.py passes all quality gates (zero dupes, zero nulls, correct dimensions).
Webhook responds with coherent answers to 3+ test queries.
  </verify>
  <done>Knowledge base re-ingested with all URL fixes and threshold updates. Quality gates pass. Bot responds coherently. Phase 1 complete.</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] All SMI/FPL thresholds verified against 2025-26 authoritative sources
- [ ] bot-ingest --replace completed successfully
- [ ] bot-ingest verify.py PASSES (zero dupes, zero nulls, 1536-dim)
- [ ] Webhook sanity check: 3+ queries return coherent responses
- [ ] Chunk count within expected range (~1,300-1,500)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- SMI/FPL thresholds current for 2025-26 (or latest available with note)
- Knowledge base re-ingested to production pgvector
- Quality gates pass
- Bot responds coherently post-ingest
- Phase 1: Knowledge Refresh complete
</success_criteria>

<output>
After completion, create `.planning/phases/01-knowledge-refresh/01-02-SUMMARY.md`
</output>

---
phase: 00-audit-baseline
plan: 01
type: execute
---

<objective>
Establish current state and measurable baseline before any changes to KiddoBot.

Purpose: Capture the "before" snapshot so every subsequent phase can prove improvement. Without a baseline, we can't measure success.
Output: Archived audit report in `.planning/`, documented feature inventory, bot-eval baseline score with archived results.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@BOT-AUDIT-kiddobot-2026-02-16.md

**Production-first doctrine:** All code changes on VPS via SSH. Dev repos are read-only.
**Bot registry:** kiddobot table = `kiddobot.document_chunks`, content = `chunk_text`, embedding = `embedding`
**Bot-eval scripts:** `~/.claude/commands/bot-eval/scripts/`
**Core suite:** `~/.claude/commands/bot-eval/assets/kiddobot-core-suite.json` (35 queries)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Archive audit report and document feature inventory</name>
  <files>.planning/phases/00-audit-baseline/AUDIT-SNAPSHOT.md</files>
  <action>
    1. Copy the audit report into the phase directory:
       `cp BOT-AUDIT-kiddobot-2026-02-16.md .planning/phases/00-audit-baseline/AUDIT-SNAPSHOT.md`

    2. Append a "Feature Inventory" section to AUDIT-SNAPSHOT.md documenting:
       - **Modes:** 3 (calculator, personalized, programs)
       - **Webhooks:** `/webhook/kiddobot` (chat), `/webhook/kiddobot-programs` (program finder)
       - **Shared components in use:** ChatMessage.jsx, DecisionTreeView.jsx
       - **Shared components NOT in use:** getMarkdownComponents, WizardStepper, react-markdown, remark-gfm
       - **Features present:** gradient bubbles, cross-tool CTAs, mode switching, error handling, basic markdown rendering
       - **Features missing:** pill-style source citations, responsive layout CSS, shared markdown renderer
       - **DB stats:** 1,390 chunks, 0 dupes, 0 nulls, 1536-dim embeddings
       - **URL health:** 154 healthy (62%), 44 redirected (18%), 48 broken (19%), 3 slow (1%)

    3. Record the overall audit score (84/100) and per-category scores as the Phase 0 baseline.

    Do NOT modify any source code. This is documentation only.
  </action>
  <verify>File exists at `.planning/phases/00-audit-baseline/AUDIT-SNAPSHOT.md` and contains both the original audit report and the appended Feature Inventory section.</verify>
  <done>AUDIT-SNAPSHOT.md exists with full audit report + feature inventory. All 5 category scores documented. All 3 modes listed. Component parity (2/6) and feature parity (5/7) recorded.</done>
</task>

<task type="auto">
  <name>Task 2: Run bot-eval core regression baseline</name>
  <files>.planning/phases/00-audit-baseline/EVAL-BASELINE.md</files>
  <action>
    1. Run the kiddobot core evaluation suite in embedding mode:
       ```bash
       cd ~/.claude/commands/bot-eval
       python3 scripts/run-eval.py \
         --core --bot kiddobot --mode embedding \
         --output /tmp/kiddobot-eval-baseline.json --archive
       ```
       This uses the pre-built 35-query kiddobot core suite against pgvector embeddings via SSH to VPS.

    2. Generate the baseline report:
       ```bash
       python3 scripts/generate-report.py \
         --results /tmp/kiddobot-eval-baseline.json \
         --output /tmp/kiddobot-baseline-report.md
       ```

    3. Copy the report into the phase directory:
       `cp /tmp/kiddobot-baseline-report.md .planning/phases/00-audit-baseline/EVAL-BASELINE.md`

    4. Log to history for longitudinal tracking:
       ```bash
       python3 scripts/log-history.py \
         --results /tmp/kiddobot-eval-baseline.json \
         --bot kiddobot
       ```

    If run-eval.py fails with SSH connection errors, verify VPS is reachable (`ssh vps "echo ok"`) and that Supabase container is running (`ssh vps "docker ps | grep supabase-db"`).
    If the core suite file is missing, check `~/.claude/commands/bot-eval/assets/kiddobot-core-suite.json`.
  </action>
  <verify>
    - `/tmp/kiddobot-eval-baseline.json` exists and contains 35 evaluated queries
    - `.planning/phases/00-audit-baseline/EVAL-BASELINE.md` exists with score breakdown
    - `~/.claude/data/eval-history/` contains archived results
  </verify>
  <done>Bot-eval baseline captured with overall coverage score. Results archived for future `--baseline auto` comparisons. History logged for longitudinal tracking. EVAL-BASELINE.md shows per-category scores across all 35 core queries.</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] AUDIT-SNAPSHOT.md exists with full audit + feature inventory
- [ ] EVAL-BASELINE.md exists with bot-eval scores
- [ ] Eval results archived to `~/.claude/data/eval-history/`
- [ ] History logged via `log-history.py`
- [ ] No code changes made (this phase is assessment only)
</verification>

<success_criteria>

- Both baseline documents created in `.planning/phases/00-audit-baseline/`
- Audit score documented: 84/100 overall
- Bot-eval baseline score captured with 35 queries evaluated
- Results archived for future comparison (`--baseline auto` will find them)
- Phase 0 complete — ready for Phase 1: Knowledge Refresh
</success_criteria>

<output>
After completion, create `.planning/phases/00-audit-baseline/00-01-SUMMARY.md`:

# Phase 0 Plan 1: Audit & Baseline Summary

**[One-liner: what the baseline scores are]**

## Accomplishments

- Archived audit report with feature inventory
- Captured bot-eval baseline (X% coverage across 35 queries)
- Results archived for longitudinal tracking

## Files Created/Modified

- `.planning/phases/00-audit-baseline/AUDIT-SNAPSHOT.md` - Full audit + feature inventory
- `.planning/phases/00-audit-baseline/EVAL-BASELINE.md` - Bot-eval baseline report
- `~/.claude/data/eval-history/kiddobot-*.json` - Archived eval results

## Decisions Made

None — assessment only.

## Issues Encountered

[Any eval failures, SSH issues, or unexpected scores]

## Next Step

Phase 0 complete. Ready for Phase 1: Knowledge Refresh.
</output>

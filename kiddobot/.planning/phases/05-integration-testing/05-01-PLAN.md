---
phase: 05-integration-testing
plan: 01
type: execute
---

<objective>
Comprehensive integration testing of all KiddoBot modes, tools, and cross-tool flows after Phases 1–4 overhaul.

Purpose: Verify that knowledge refresh, tool rebuilds, and UI polish didn't introduce regressions — and that the bot meets quality standards before production deploy.
Output: Bot-eval scores (embedding + webhook), baseline comparison, browser verification of all interactive flows.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Auto-selected based on dependency graph (all phases affect 05):
@.planning/phases/00-audit-baseline/00-01-SUMMARY.md
@.planning/phases/00-audit-baseline/EVAL-BASELINE.md
@.planning/phases/03-tool-rebuilds/03-01-SUMMARY.md
@.planning/phases/03-tool-rebuilds/03-02-SUMMARY.md
@.planning/phases/04-ui-polish/04-01-SUMMARY.md
@.planning/phases/04-ui-polish/04-02-SUMMARY.md

**Phase 0 Baseline (comparison target):**
- 35 queries, 100% coverage: 34 Strong (97.1%), 1 Acceptable (2.9%), 0 Weak
- Acceptable query: "My child has a fever..." (off-topic, similarity 0.3638)
- Overall audit score: 84/100

**Constraining decisions:**
- [Phase 1]: 935 chunks re-ingested with fixed URLs and updated thresholds
- [Phase 3]: EligibilityCalculator now data-driven via JSON; CountyRRLookup added; cross-tool CTAs wired
- [Phase 4]: Violet accent (not pink); mobile-first responsive; violet added to shared ChatMessage, DecisionTreeView, RAGButton

**Note on baseline comparison:** Phase 0 baseline is already 97.1% strong. The roadmap target of "improvement >= 5 points" is unreachable from that ceiling. Success = maintaining >= 97% strong with 0 weak scores, proving overhaul preserved quality.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run bot-eval embedding + webhook + baseline comparison</name>
  <files>None (evaluation only — no code changes)</files>
  <action>
Run three evaluations sequentially on VPS via the bot-eval skill infrastructure:

1. **Embedding eval (core suite):**
   Run `/bot-eval --bot kiddobot --mode embedding --core` against the 35-query core suite.
   - Must score >= 80% coverage (strong + acceptable)
   - Record exact strong/acceptable/weak counts
   - Compare against Phase 0 baseline: 34S/1A/0W

2. **Webhook eval (live endpoint):**
   Run `/bot-eval --bot kiddobot --mode webhook`
   - Tests both webhooks: `/kiddobot` (main chat) and `/kiddobot-programs` (program finder)
   - Both must respond with 200 status
   - Response time < 15s (main chat was 7.45s at audit)
   - Response body must contain relevant content (not error messages)

3. **Baseline comparison:**
   Compare current results against Phase 0 baseline stored in `~/.claude/data/eval-history/`.
   - Report delta: any queries that changed score category (strong→acceptable, etc.)
   - Flag any NEW weak scores as regressions
   - If any regressions found, document them for investigation before Phase 6

Save evaluation results to `.planning/phases/05-integration-testing/EVAL-RESULTS.md` with:
- Side-by-side baseline vs. current scores per query
- Summary delta table
- Pass/fail verdict
  </action>
  <verify>
EVAL-RESULTS.md exists in phase directory with:
- Embedding eval: 0 weak scores, coverage >= 80%
- Webhook eval: both endpoints respond 200
- Baseline comparison: no regressions (no strong→weak transitions)
  </verify>
  <done>All three evaluations complete. Results documented. 0 weak scores. Both webhooks healthy. No regressions from Phase 0 baseline.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>All automated evaluations passed — now need browser verification of the interactive features rebuilt in Phases 3-4</what-built>
  <how-to-verify>
    1. Open: https://vanderdev.net/kiddobot in a browser
    2. **Mode transitions:** Click each of the 3 mode buttons (Chat, Eligibility Calculator, Program Finder). Each should:
       - Switch instantly with no flash/flicker
       - Show violet accent consistently (not blue, not pink)
       - Display the correct tool UI
    3. **EligibilityCalculator tool:**
       - Select a family size, enter an income, click Calculate
       - Verify threshold results display with violet accent
       - Verify the "Check what programs you qualify for →" CTA button appears
       - Click the CTA — should navigate to Program Finder mode
    4. **ProgramFinder tool:**
       - Verify program cards display correctly
       - Click a program card's details — should expand with collapsible content
       - Verify county R&R lookup shows dropdown with 58 counties
       - Select a county — verify R&R agency info appears (name, phone, website if available)
    5. **Cross-tool CTAs:**
       - From Calculator results, click "Check programs →" — goes to Program Finder
       - From Program Finder, click "Check eligibility →" — goes to Calculator
       - From either tool, click "Ask KiddoBot →" — goes to Chat mode
    6. **Chat mode:**
       - Send "What is CalWORKs childcare?" — should get a markdown-formatted response with violet accent
       - Verify source citations appear as pills (not raw URLs)
       - Verify message bubbles have gradient styling
    7. **Edge cases (in Chat mode):**
       - Send empty message (just spaces) — should not crash or send
       - Send a very long message (paste 500+ chars) — should handle gracefully
       - Send special characters: `<script>alert('xss')</script>` — should display as text, not execute
    8. **Responsive layout:**
       - Resize browser to ~375px width — mode buttons should stack to 1 column
       - Resize to ~768px — mode buttons should show 2 columns
       - Check no horizontal scrollbar appears at any width
    9. **Console check:** Open browser DevTools Console tab — verify no JavaScript errors (warnings OK)
  </how-to-verify>
  <resume-signal>Type "approved" if all checks pass, or describe specific issues found</resume-signal>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] Bot-eval embedding: 0 weak, coverage >= 80%
- [ ] Bot-eval webhook: both endpoints 200, response < 15s
- [ ] No regressions from Phase 0 baseline
- [ ] Browser verification approved by human
- [ ] No console errors in browser DevTools
- [ ] EVAL-RESULTS.md saved with full comparison data
</verification>

<success_criteria>

- All automated evaluations pass with 0 weak scores
- Both webhooks respond successfully
- No regressions from Phase 0 baseline (34S/1A/0W)
- Human approves all browser verification checks
- All cross-tool CTAs navigate correctly
- No JavaScript console errors
- Phase 5 complete — ready for Phase 6: Production Deploy
</success_criteria>

<output>
After completion, create `.planning/phases/05-integration-testing/05-01-SUMMARY.md`:

# Phase 5 Plan 1: Integration & E2E Summary

**[Substantive one-liner about test results]**

## Accomplishments

- Bot-eval embedding scores (vs baseline)
- Webhook health check results
- Browser verification outcomes

## Files Created/Modified

- `.planning/phases/05-integration-testing/EVAL-RESULTS.md` - Evaluation comparison

## Decisions Made

[Any issues found and resolution decisions]

## Issues Encountered

[Regressions or failures and how they were resolved]

## Next Step

Phase 5 complete — ready for Phase 6: Production Deploy
</output>

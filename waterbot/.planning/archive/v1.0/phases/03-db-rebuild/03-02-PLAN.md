---
phase: 03-db-rebuild
plan: 02
type: execute
---

<objective>
Execute the WaterBot database rebuild using the strategy decided in 03-01. Back up existing data, clear/prepare the table, re-embed all overhauled content via the ingestion pipeline, rebuild the IVFFlat index, and validate with integrity checks and similarity search tests.

Purpose: This is the point where all Phase 1-2 content work becomes live. The overhauled, URL-rich knowledge base replaces the old content in production.
Output: Fully rebuilt waterbot_documents table with all overhauled topics, functional IVFFlat index, validated similarity search.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior plan in this phase:
@.planning/phases/03-db-rebuild/03-01-SUMMARY.md

# Auto-selected based on dependency graph:
@.planning/phases/02-content-overhaul/02-04-SUMMARY.md

# Key files:
@scripts/ingest_waterbot_content.py
@rag-content/waterbot/

**Tech stack available:** Python 3, OpenAI embeddings (text-embedding-3-small, 1536 dims), PostgreSQL 15.8.1 + pgvector 0.8.0, SSH pipeline
**Established patterns:** SSH + docker exec + psql, dollar-quoted SQL (CONTENT_END_12345), IVFFlat REINDEX after bulk inserts, ingest_waterbot_content.py auto-rebuilds index
**Constraining decisions:**
- Phase 03-01: Rebuild strategy decision (clean-slate or preserve-enhance)
- Keep embedding model: text-embedding-3-small (1536 dims) — out of scope to change
- Keep table schema: content (TEXT), metadata (JSONB), embedding (vector(1536))
- Bot is live: minimize empty-DB window
</context>

<tasks>

<task type="auto">
  <name>Task 1: Execute database rebuild</name>
  <files>scripts/ingest_waterbot_content.py (may need minor edits to exclude url_registry.json)</files>
  <action>
  **Pre-flight checks:**
  - Verify `OPENAI_API_KEY` is set: `echo $OPENAI_API_KEY | head -c 8` (should show sk-proj- prefix)
  - Verify SSH: `ssh vps "echo ok"`
  - Verify psql: `ssh vps "docker exec -i supabase-db psql -U postgres -d postgres -c 'SELECT 1;'"`
  - Check if `ingest_waterbot_content.py` would pick up `url_registry.json` — if its glob matches it, add a skip condition (the file has a different structure and would error or produce garbage embeddings)

  **If clean-slate (expected):**
  1. Back up current data locally:
     `ssh vps "docker exec -i supabase-db psql -U postgres -d postgres -c \"COPY public.waterbot_documents(id, content, metadata, created_at) TO STDOUT WITH CSV HEADER\"" > /tmp/waterbot_backup_$(date +%Y%m%d).csv`
     (Embedding vectors are too large for CSV — back up row data only. Full restore would need re-embedding anyway.)
  2. Verify backup file is non-empty and has expected row count
  3. TRUNCATE table:
     `ssh vps "docker exec -i supabase-db psql -U postgres -d postgres -c 'TRUNCATE public.waterbot_documents RESTART IDENTITY;'"`
  4. Verify empty:
     `ssh vps "docker exec -i supabase-db psql -U postgres -d postgres -c 'SELECT COUNT(*) FROM public.waterbot_documents;'"` → must be 0
  5. Run ingestion: `python3 scripts/ingest_waterbot_content.py`
     - Script auto-generates OpenAI embeddings per document
     - Script auto-inserts via SSH pipeline
     - Script auto-rebuilds IVFFlat index after successful inserts
  6. Monitor output for errors — expect ~179 successful inserts across ~33 files

  **If preserve-enhance:**
  1. Same backup step as above
  2. Delete old markdown-chunked rows only:
     `ssh vps "docker exec -i supabase-db psql -U postgres -d postgres -c \"DELETE FROM public.waterbot_documents WHERE metadata ? 'document_id';\"`
  3. Run ingestion for new batch content
  4. REINDEX manually if script doesn't auto-trigger:
     `ssh vps "docker exec -i supabase-db psql -U postgres -d postgres -c 'REINDEX INDEX public.waterbot_documents_embedding_idx;'"`
  </action>
  <verify>
  - Ingestion script exits without errors
  - `SELECT COUNT(*) FROM public.waterbot_documents;` returns expected count (~179)
  - IVFFlat REINDEX completed (check script output for "REBUILDING IVFFLAT INDEXES ... OK")
  </verify>
  <done>All overhauled content ingested. Row count matches expected document count. IVFFlat index rebuilt. No insertion errors.</done>
</task>

<task type="auto">
  <name>Task 2: Validate rebuild with integrity checks and similarity search</name>
  <files>scripts/ (read only)</files>
  <action>
  **Data integrity checks (SSH):**
  - Row count: `SELECT COUNT(*) FROM public.waterbot_documents;`
  - No nulls: `SELECT COUNT(*) FROM public.waterbot_documents WHERE content IS NULL OR metadata IS NULL OR embedding IS NULL;` → must be 0
  - Metadata consistency: `SELECT metadata->>'category' AS cat, COUNT(*) FROM public.waterbot_documents GROUP BY 1 ORDER BY 2 DESC;` → all rows should have category
  - Content has URLs: `SELECT COUNT(*) FROM public.waterbot_documents WHERE content LIKE '%](http%';` → expect majority of rows
  - Content has Take Action: `SELECT COUNT(*) FROM public.waterbot_documents WHERE content LIKE '%Take Action%';` → expect majority of rows
  - Avg content length: `SELECT AVG(LENGTH(content))::int FROM public.waterbot_documents;` → expect ~1,500-3,000 chars

  **Similarity search validation:**
  Generate embeddings locally for 3 test queries, then run cosine similarity via SSH:

  1. "how do I check my water quality" — expect water quality testing topic
  2. "PFAS contamination in drinking water" — expect PFAS/pollutants topic
  3. "how to file a complaint about my water" — expect complaints/public resources topic

  For each query:
  - Generate embedding via OpenAI API (same model: text-embedding-3-small)
  - Run: `SELECT metadata->>'topic' AS topic, LEFT(content, 200), 1 - (embedding <=> '{vector}') AS similarity FROM public.waterbot_documents ORDER BY embedding <=> '{vector}' LIMIT 3;`
  - Verify top result is semantically relevant (correct topic area)
  - Verify similarity score is reasonable (>0.30 for ACCEPTABLE threshold)

  **Summary report:**
  Present results in a table: row count, null check, URL coverage %, Take Action coverage %, similarity search results (3 queries × top result topic + score).
  </action>
  <verify>All integrity checks pass. All 3 similarity queries return relevant top results with scores above 0.30.</verify>
  <done>DB rebuild validated: correct row count, zero nulls, URL-rich content confirmed, IVFFlat index returns relevant results for test queries. Phase 3 complete — DB ready for Phase 4 (System Prompt).</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] Database backup created before any destructive operations
- [ ] All overhauled content ingested successfully (no insertion errors)
- [ ] IVFFlat index rebuilt
- [ ] Row count matches expected document count
- [ ] No null content/metadata/embedding fields
- [ ] Content contains inline URLs (verified via SQL)
- [ ] Content contains Take Action sections (verified via SQL)
- [ ] Similarity search returns relevant results for 3 test queries
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- waterbot_documents contains all overhauled content (~179 docs)
- IVFFlat index functional — similarity queries return relevant, high-scoring results
- No data integrity issues (nulls, wrong dimensions, missing metadata)
- Phase 3 complete — DB ready for system prompt update (Phase 4)
</success_criteria>

<output>
After completion, create `.planning/phases/03-db-rebuild/03-02-SUMMARY.md`
</output>
